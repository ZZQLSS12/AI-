# AI导论大作业
我负责了QQ音乐爬取，数据集构建，深度学习和XGBoost模型的构建工作，实现了音乐分类器。项目其余部分由我的队友负责。  
在完成我们的工作之前，我们借鉴了GTZAN数据集以及相关工作。但是GTZAN数据集给我们的工作带来了一个巨大的隐患，GTZAN数据集中，通过将30s的音乐片段，划分成10个3s的片段，来扩增数据集。我们也采用了这样的方法，可是在我们的后期测试中发现，这样的方法会产生过拟合现象。  
简而言之，模型学到了同一首音乐不同片段之间的相似性，造成了准确率虚高的问题。验证方法为：控制数据集大小相近，但是一组是每个片段均来自不同音乐；另一组存在多个片段来自同一首音乐的问题，经测试，前者比后者的测试集准确率低很多。但是由于大作业时间有限，我们没有彻底解决这个问题。  
但是，由于GTZAN数据集也使用了这样的方法，并且长久以来似乎也没有被修改，我对这种数据集扩增方法的有效性持开放态度，或许真的有效？  
